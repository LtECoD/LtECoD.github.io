[{"content":"生成式模型可以抽象成数据传输游戏：Alice要向Bob发送一些数据，而他们的目标是发送的损失 尽量小，所谓损失就是编码的位数 。\n数据传输视角下的语言模型 假设Alice和Bob有一个共同的词表$\\mathcal{V}$。现在，Alice要给Bob发送一段包含$n$个token的文本$\\boldsymbol{x}=(x_1, \\cdots, \\boldsymbol{x}_n)$。 注意，Alice并非将整段文本直接发送给Bob，而是逐个token发送（与LM的工作方式一样）。假设Bob能够根据已经接收到的token预测Alice下一个将要发送的token，也就是说Bob有一个$\\mathcal{V}$上的分布： $$P(x_i|x_{\u0026lt;i})$$ 那么发送每个token的损失就是根据条件概率分布$p$对这个token进行最优编码的位数，即条件概率的负对数，而发送这段文本的损失等价于发送所有token的损失： $$-\\sum_{i=1}^{n}\\log P(x_i|x_{\u0026lt;i})=-\\log\\prod_{i=1}^{n} P(x_i|x_{\u0026lt;i})=-\\log P(\\boldsymbol{x})$$ 注：以上的对数函数$\\log$均以2为底。 没错，根据以上数据传输游戏的目标，我们可以推出语言模型的损失函数。这个框架同样适用于VAE。 VAE的损失函数 $$ \\begin{align*} -\\log P(\\boldsymbol{x}) \u0026amp;= -\\log\\int P(\\boldsymbol{x},\\boldsymbol{z})d\\boldsymbol{z} \\\\ \u0026amp;=-\\log\\int P(\\boldsymbol{x},\\boldsymbol{z})\\frac{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}d\\boldsymbol{z} \\\\ \u0026amp;=-\\log\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})} \\frac{P(\\boldsymbol{x},\\boldsymbol{z})}{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})} \\\\ \u0026amp;\\leq -\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}[\\log P_{\\boldsymbol{\\phi}}(\\boldsymbol{x}|\\boldsymbol{z}) + \\log \\frac{P(\\boldsymbol{z})}{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}] \\\\ \u0026amp;=-\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P_{\\boldsymbol{\\phi}}(\\boldsymbol{x}|\\boldsymbol{z}) + \\int P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})\\log\\frac{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}{P(\\boldsymbol{z})} d\\boldsymbol{z} \\\\ \u0026amp;=-\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P_{\\boldsymbol{\\phi}}(\\boldsymbol{x}|\\boldsymbol{z}) + \\text{KL}[P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})|P(\\boldsymbol{z})] \\end{align*} $$ 注: 此处$P(\\cdot;\\boldsymbol{\\theta})$代表使用参数为$\\boldsymbol{\\theta}$的神经网络对$P(\\cdot)的$估计。另外， 带有误差项的推导可参考文献[1]中的公式9-16。 总的来说，VAE的优化目标包含两个部分，分别是在最大化样本$x$的条件概率似然，以及最小化隐变量$z$的后验分布和先验分布的KL散度。我们同样可以从数据传输的角度理解VAE。\n数据传输视角下的VAE 在新一局游戏中，Alice首先将要发送的内容$x$转化成一个分布$P_\\boldsymbol{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$，这个转化过程是由一个参数为$\\boldsymbol{\\theta}$的神经网络完成的。然后，Alice从这个分布中采样得到变量$z$并发送给Bob，Bob利用一个参数为$\\boldsymbol{\\phi}$的神经网络对$z$做解码，从而得到x的条件概率分布$P_\\boldsymbol{\\phi}(x|z)$。 另一方面，Bob并不知道Alice的分布$P_\\boldsymbol{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$长什么样，但他拥有一个预定义的关于$\\boldsymbol{z}$的分布$P(\\boldsymbol{z})$。 那么这个传输过程的整体损失就包括两个部分：Alice发送$\\boldsymbol{z}$的损失以及Bob解码得到$\\boldsymbol{x}$的损失。\n先看第一个方面，Alice发送的变量$\\boldsymbol{z}$服从的分布$P_\\boldsymbol{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$，理想情况下，发送的$\\boldsymbol{z}$的最低损失是$-\\mathop{\\mathbb{E}}\\limits_{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})$，也就是发送$z$最少需要的位数。不过，我们应该意识到$P(\\boldsymbol{z})$与$P_\\boldsymbol{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$并不一致，所以实际需要的位数为$-\\mathop{\\mathbb{E}}\\limits_{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P(\\boldsymbol{z})$，那么额外的损失就是: $$ \\mathop{\\mathbb{E}}\\limits_{P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}[\\log P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})-\\log P(\\boldsymbol{z})] = \\text{KL}[P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})|P(\\boldsymbol{z})] $$ 再来看第二个方面的损失。Bob将$\\boldsymbol{z}$解码得到$\\boldsymbol{x}$，平均所需的位数就是； $$ -\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P_{\\boldsymbol{\\phi}}(\\boldsymbol{x}|\\boldsymbol{z}) $$ 综上，传输游戏的目标就是最小化整体的损失: $$ -\\mathop{\\mathbb{E}}\\limits_{ P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})}\\log P_{\\boldsymbol{\\phi}}(\\boldsymbol{x}|\\boldsymbol{z})+\\text{KL}[P_{\\boldsymbol{\\theta}}(\\boldsymbol{z}|\\boldsymbol{x})|P(\\boldsymbol{z})] $$ 以上的内容说明，我们完全可以从数据传输的角度理解VAE的优化目标。既然VAE能纳入到这个数据传输游戏框架中，那么Diffusion模型也能纳入到里面去，因为Diffusion完全可以根据VAE推导出（参考文献[1]）。\n参考文献 Calvin L, et al. Understanding Diffusion Models: A Unified Perspective, arXiv:2208.11970 ","permalink":"https://ltecod.github.io/posts/2023/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/","summary":"生成式模型可以抽象成数据传输游戏：Alice要向Bob发送一些数据，而他们的目标是发送的损失 尽量小，所谓损失就是编码的位数 。 数据传输视角下的","title":"数据传输视角下的语言模型和VAE"},{"content":"1.1 人工智能不仅仅是决策 在思考深度生成建模之前，先看一个简单的例子：假如我们已经训练了一个对动物图像$\\boldsymbol{x}\\in\\mathbb{Z}^D$分类的深度神经网络，图像的标签表示为$y\\in\\mathcal{Y}$, 其中$\\mathcal{Y}$={cat, dog, horse}；假设这个神经网络已训练完成且能够对一个样本进行正确分类。目前为止还不错，对吧？但如文献[1]所指出，在输入图像中添加一些噪声可能会导致完全错误的分类结果。图1.1展示了一个添加噪声改变预测标签概率的例子；然而，加入的噪声几乎没有改变图像的内容（至少对人类来说）。\n这个例子表明，用于参数化条件分布$p(y|\\boldsymbol{x})$的神经网络似乎缺乏对图像的语义理解。由此，我们可以认为判别式学习对于决策系统或人工智能是不够的。对一个机器学习系统来说，如果无法理解或表达所处环境的不确定性，那么它做出的决策是不可靠的。例如：当少量的噪音就能改变系统内部的信念并导致决策方向的偏移，我们如何信任这样的系统？当系统对所处环境一无所知，我们如何与之沟通？\n为了说明“不确定性 （uncertainty）”和“理解 （understanding）”两个概念，以二分类任务为例，类别分别用orange和blue两种颜色表示。假定有一些二维标注样本（图1.2左），还有一个待测试样本（图1.2中的✖️）。我们有两种方式构建分类系统：第一是基于条件概率$p(y|\\boldsymbol{x})$（图1.2中）在标注样本上学习；第二则是通过联合分布$p(\\boldsymbol{x},y)=p(y|\\boldsymbol{x})p(\\boldsymbol{x})$（图1.2右）在标注样本上学习。\n如果使用判别式方法，即学习条件概率分布$(y|\\boldsymbol{x})$，那么可以清晰地画出两个类别之间的分界线。然后可以看到✖️距离orange区域非常远，所以分类器认为这个样本属于blue类的概率更大，说明分类器对分类结果非常确定。\n但是，如果额外学习一个边缘概率$p(\\boldsymbol{x})$，可以看到✖️不仅距离类别边界线非常远，而且距离标注的blue样本也非常远。这说明✖️远离标注样本高概率出现的区域，因此✖️的边缘概率$p(\\boldsymbol{x}=\\times)$取值低，则联合概率$p(\\boldsymbol{x}=\\times,y=\\text{blue})$同样取值低，因此模型对分类的结果并不确定。\n这个例子表明，理解所处环境是可靠人工智能系统的特征之一。针对这个目标，只进行判别式学习是不够的，还应使用概率论语言量化对周围环境的信念[2, 3]，所以我们认为对分布$p(\\boldsymbol{x})$进行建模是非常重要的，它有如下的必要性： 生成式建模的作用 1.评估对$\\boldsymbol{x}$的置信度或对环境的不确定程度；\n2.对决策结果进行加权；\n3.生成新的数据实例。 通常来讲，在深度学习中，生成式模型指代哪些可以生成数据实例的模型，但我们尝试展示了生成模型更广泛的应用，这对于构建人工智能系统来说或许非常重要。此外，对数据的生成式过程建模对与理解感兴趣的现象至关重要[3，4]。针对判别任务，我们倾向于关注$p(\\boldsymbol{x},y)=p(y|\\boldsymbol{x})p(\\boldsymbol{x})$，如前所述，这比单独的条件分布更具优势。\n1.2 生成式建模可以用在什么领域？ 随着神经网络和算力的发展，深度生成建模已经成为人工智能领域的前沿方向之一。它的应用横跨多种不同的数据模态，例如：文本分析[5]、图像分析[6]、音频分析[7]，以及不同的学习范式，例如主动学习[8]、强化学习[9]。图1.3展示了深度生成建模潜在的应用。 在某些任务中，直接生成或着通过修改已有样本的特征获取新的数据实例非常重要。但在主动学习这样的任务中，找出低置信度的样本更为重要。对于强化学习情况又另当别论，生成下一步最有可能的环境状态对于Agent的行动决策非常重要。而对于医学应用，生成模型提供的信息比单纯的判别式模型更具价值。如果一个人工智能系统知道自己所不知道的，那么它就具备作为一个独立专家的可能性。\n以上例子清楚地表明，很多领域都可以从生成模型中受益。也许成熟的人工智能系统会需要多样的能力，但正如以上案例所示，我们认为生成式建模无疑是最重要的能力之一。\n1.3 如何实现生成式建模？ 在介绍了生成式建模的重要性和广泛应用性之后，我们应该思考如何用模型实现生成式建模，换句话说，如何计算我们多次提到的$p(\\boldsymbol{x})$。\n目前已有的生成式建模方法分为四类（图1.4）: 生成式模型的分类 1.自回归式生成模型（Autoregressive Gnerative Models, ARM）\n2.流模型（Flow based models）\n3.隐变量模型（Latent variable models）\n4.能量模型（Energy-based models） 我们目前所讨论的建模方法都可以不用深度神经网络实现。尽管如此，但神经网络是灵活且强大的，且被广泛用于参数化生成模型。因此，我们从现在开始主要关注深度生成模型，即基于深度神经网络构建的生成模型。\n以上对生成模型的分类仅作为帮助我们浏览本书的原则，并非一成不变。就我个人而言，我不太喜欢花太多时间对科学方法进行分类和标记，因为这一般会导致分歧和门槛。此外，还有一组基于分数匹配[12-14]的模型无法采用上述分类原则。然而，正如[14]所指出的，这些模型与隐变量模型有很多相似之处（如果我们将随机过程的连续步骤视为隐变量），因此，我们将其视为隐变量模型。\n1.3.1 自回归生成模型 在自回归生成模型中，样本的概率分布$p(\\boldsymbol{x})$以自回归的方式分解为: $$ p(\\boldsymbol{x})=p(x_0)\\prod_{i=1}^{D}p(x_i|\\boldsymbol{x}_{\u0026lt;i}),\\tag{1.1} $$\n其中，$\\boldsymbol{x}_{\u0026lt;i}$表示$\\boldsymbol{x}$中索引小于$i$的部分。\n计算所有的条件概率$p(x_i|\\boldsymbol{x}_{\u0026lt;i})$是低效的。不过我们可以借助于因果卷积[7,15,16]等技术。第2章中深入讨论了自回归模型。\n1.3.2 流模型 变量替换定理通过可逆变换$f$对随机变量的密度进行变换，为生成式模型提供了一种计算概率分布的方法[17]： $$ p(\\boldsymbol{x}) = p(\\boldsymbol{z}=f(\\boldsymbol{x}))|\\boldsymbol{J}_{f(\\boldsymbol{x})}|,\\tag{1.2} $$\n其中，$\\boldsymbol{J}_{f(\\boldsymbol{x})}$表示Jacobian矩阵。\n虽然$f$可由神经网络参数化，但神经网络的运算必须支持计算Jacobian矩阵，因此架构十分受限。 线性体积等价变换（linear, volume-preserving transformations）[18,19]是早期出现的变换方法，这种变换的Jacobian矩阵行列式$|\\boldsymbol{J}_{f(\\boldsymbol{x})}|=1$。后续工作基于矩阵行列式设计非线性变换，包括planar流[20]和Sylvester流[21,22]。另一类方法侧重于建模可逆变换，从而使Jacobian矩阵可计算，例如使用耦合层的RealNVP[23]。最近的工作利用可逆约束使任意神经网络都可以计算Jacobian矩阵行列式的近似[24-26]。\n针对离散化数据，概率质量函数的体积无法进行变换，因此，变量替换定理采用如下形式： $$ p(\\boldsymbol{x}) = p(\\boldsymbol{z}=f(\\boldsymbol{x})).\\tag{1.3} $$ 整数离散流提出使用带有舍入运算符的仿射耦合层来保证整数输出[27]。[28]对仿射偶合层做了进一步扩展。\n所有利用变量替换定理的生成式模型统称为基于流的模型或简称为流模型。我们会在第三章讨论流模型。\n1.3.3 隐变量模型 隐变量模型的基本思想是假设存在一个低维的隐空间并且数据的生成过程为： $$ \\begin{aligned} \u0026amp;\\boldsymbol{z}\\sim p(\\boldsymbol{z}) \\\\ \u0026amp;\\boldsymbol{x}\\sim p(\\boldsymbol{x}|\\boldsymbol{z}). \\end{aligned} $$ 其中隐变量$\\boldsymbol{z}$就是样本$\\boldsymbol{x}$在低维隐空间中的映射。\n最为人熟知的隐变量模型可能是概率主成分分析[29]（pPCA），其假设$p(\\boldsymbol{z})$和$p(\\boldsymbol{x}|\\boldsymbol{z})$都是高斯分布，而且$\\boldsymbol{x}$和$\\boldsymbol{z}$之间是线性相关的。\n变分自编码器（Variationa Auto-Encoder，VAE）[30,31]是一种非线性版的pPCA。VAE使用变分推断估计后验概率$p(\\boldsymbol{z}|\\boldsymbol{x})$，并且利用神经网络对概率分布进行参数化。自从Kingma和Welling的论文[30]以及Rezende等人的论文[31]发表之后，很多VAE的扩展或变种被提出，包括对后验的改进[19,21,22,32]、对先验的改进[33,34]以及对解码器的改进[35]。也有一些工作对隐空间的拓扑结构做了约束，例如，球面隐空间[36]。无论是VAE还是pPCA，其中的所有分布都需要提前确定好，因此，这些模型也被称为预定义的（prescribed）模型，我们将在第四章讨论隐变量模型。\n目前为止，自回归模型、流模型以及pPCA和VAE都以最大化对数概率似然为目标，这与数据分布和模型分布之间的KL散度密切相关。另一种不同的方法采用对抗损失，使用一个判别器$D(\\cdot)$判断输入的样本是真实的样本还是由生成器隐式生成的样本，即$p(\\boldsymbol{x}|\\boldsymbol{z})=\\sigma(\\boldsymbol{x}-G(\\boldsymbol{z}))$，其中$\\sigma(\\cdot)$表示狄拉克函数。这一类模型称为隐式（implicit）模型。生成对抗网络（Generative Adversarial Networks, GANs）是典型的隐式模型，能够生成逼真的图像，是最成功的深度生成模型之一。详见第七章。\n1.3.4 能量模型 物理学中的能量函数$E(\\boldsymbol{x})$以及玻尔兹曼分布，为生成式建模提供了一个有趣的角度: $$ p(\\boldsymbol{x})=\\frac{\\exp(-E(\\boldsymbol{x}))}{Z} $$ 其中$Z=\\sum_{\\boldsymbol{x}}\\exp(-E(\\boldsymbol{x}))$表示配分函数。分布由幂能量函数定义，该幂能量函数通过配分函数$Z$归一化作为概率取值。尽管深入到物理学中会发现更多关于能量函数的内容，但我们不需要深究。[37]是研究能量模型一个很好的起点。\n借由能量函数表示概率分布的生成模型称为能量模型（energy-based models，EBMs）。EBM背后的主要思想是建模能量函数并计算（更确切地说是近似地计算）配分函数。玻尔兹曼机（Boltzmann Machines）是一种典型的能量模型，它利用双线性映射作为能量函数，即$E(\\boldsymbol{x})=\\boldsymbol{x}^\\top\\boldsymbol{W}\\boldsymbol{x}$。在玻尔兹曼机中引入隐变量就是受限玻尔兹曼机[41]$E(\\boldsymbol{x}, \\boldsymbol{z})=\\boldsymbol{x}^\\top\\boldsymbol{W}\\boldsymbol{z}$。玻尔兹曼机的概念可以进一步扩展到$\\boldsymbol{x}$和$y$的联合分布，并用于判别式分类，例如受限玻尔兹曼机分类器[42]。研究表明，任意神经网络都可以用于参数化联合分布[43]。我们将在第六章中讨论能量模型。\n1.3.5 总结 表1.1基于四个要素对比了生成式模型，包括训练的稳定性、是否需要计算似然函数、数据压缩是否无损、是否能用于表示学习：\n所有基于似然概率的模型（自回归模型，流模型、能量模型，以及诸如VAE的预定义隐变量模型）均能够进行相对稳定的训练，而GAN这类隐式模型的训练过程则不稳定。对于VAE这样的预定义隐变量模型，无法精确地计算出似然概率，只能得到它的一个下界。与之相似，EBM需要计算配分函数才能得到思然概率，而计算配分函数相当困难。因此，EBM顶多可以提供未归一化的能量或近似概率。ARM能够计算似然概率；然而，自回归的方式导致采样过程极其缓慢。EBM需要基于蒙特卡罗方法生成样本，所以在高维数据上效率会很低。从数据压缩的角度来看，VAE对数据做了有损压缩（低维隐空间）。另一方面，ARM和流模型可以用于无损压缩，因为它们能够提供精确的似然概率用于密度估计。虽然隐式模型则不能直接用于压缩，不过也有工作尝试使用GAN改进图像压缩[44]。流模型、预定义隐变量模型和EBM（如果使用隐变量）都可以用于表示学习，即学习一组随机变量，这些变量以某种方式总结数据或对数据中的元素进行解耦。至于什么是好的数据表示，这是另外的问题，可参考[45]。\n1.4 本书的目的和内容 本书旨在介绍深度生成建模这一领域，让你相信生成建模的哲学，并展示它的美！深度生成建模将概率论、统计学、概率机器学习和深度学习结合在一个框架中。为了更好地理解本书的内容，代数和微积分、概率论和统计学、机器学习和深度学习的基础以及Python编程等方面的知识是必要的。书中所有代码片段均基于PyTorch编写，不过Keras、Tensorflow或JAX深度学习框架用户也足以理解代码。\n本书不会专门回顾机器学习的基本概念以及深度神经网络的知识。我们将深入研究深度生成模型和训练算法。我们将讨论自回归模型（第2章）、流模型（第3章）、隐变量模型（第4章）、混合模型（第5章）、能量模型（第6章）和生成对抗网络（第7章），最后将介绍深度生成建模如何用于数据压缩（第8章），章节之间彼此独立，且都包含一般性的讨论和形式化的过程以及对应的代码。本书的目的是使读者真正理解深度生成式建模，不仅能推导出模型也能够用代码实现。本书的代码库为： https://github.com/jmtomczak/intro_dgm。 参考文献 Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In 2nd International Conference on Learning Representations, ICLR 2014, 2014. Christopher M Bishop. Model-based machine learning. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 371(1984):20120222, 2013. Zoubin Ghahramani. Probabilistic machine learning and artificial intelligence. Nature, 521(7553):452–459, 2015. Julia A Lasserre, Christopher M Bishop, and Thomas P Minka. Principled hybrids of generative and discriminative models. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06), volume 1, pages 87–94. IEEE, 2006. Samuel Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, pages 10–21, 2016. Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. arXiv preprint arXiv:1406.2661, 2014. Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. WaveNet: A generative model for raw audio. arXiv preprint arXiv:1609.03499, 2016. Samarth Sinha, Sayna Ebrahimi, and Trevor Darrell. Variational adversarial active learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 5972–5981, 2019. David Ha and Jürgen Schmidhuber. World models. arXiv preprint arXiv:1803.10122, 2018. GraphVAE: Towards generation of small graphs using variational autoencoders, author=Simonovsky, Martin and Komodakis, Nikos, booktitle=International Conference on Artificial Neural Networks, pages=412–422, year=2018, organization=Springer. Maximilian Ilse, Jakub M Tomczak, Christos Louizos, and Max Welling. DIVA: Domain invariant variational autoencoders. In Medical Imaging with Deep Learning, pages 322–348. PMLR, 2020. Aapo Hyvärinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research, 6(4), 2005. Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. arXiv preprint arXiv:1907.05600, 2019. Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2020. Aaron Van Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. In International Conference on Machine Learning, pages 1747–1756. PMLR, 2016. Aäron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray Kavukcuoglu. Conditional image generation with PixelCNN decoders. In Proceedings of the 30th International Conference on Neural Information Processing Systems, pages 4797–4805, 2016. Oren Rippel and Ryan Prescott Adams. High-dimensional probability estimation with deep density models. arXiv preprint arXiv:1302.5125, 2013. Laurent Dinh, David Krueger, and Yoshua Bengio. NICE: Non-linear independent components estimation. arXiv preprint arXiv:1410.8516, 2014. Jakub M Tomczak and Max Welling. Improving variational auto-encoders using householder flow. arXiv preprint arXiv:1611.09630, 2016. Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In International Conference on Machine Learning, pages 1530–1538. PMLR, 2015. Rianne Van Den Berg, Leonard Hasenclever, Jakub M Tomczak, and Max Welling. Sylvester normalizing flows for variational inference. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages 393–402. Association For Uncertainty in Artificial Intelligence (AUAI), 2018. Emiel Hoogeboom, Victor Garcia Satorras, Jakub M Tomczak, and Max Welling. The convolution exponential and generalized Sylvester flows. arXiv preprint arXiv:2006.01910, 2020. Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using Real NVP. arXiv preprint arXiv:1605.08803, 2016. Jens Behrmann, Will Grathwohl, Ricky TQ Chen, David Duvenaud, and Jörn-Henrik Jacobsen. Invertible residual networks. In International Conference on Machine Learning, pages 573–582. PMLR, 2019. Ricky TQ Chen, Jens Behrmann, David Duvenaud, and Jörn-Henrik Jacobsen. Residual flows for invertible generative modeling. arXiv preprint arXiv:1906.02735, 2019. Yura Perugachi-Diaz, Jakub M Tomczak, and Sandjai Bhulai. Invertible DenseNets with Concatenated LipSwish. Advances in Neural Information Processing Systems, 2021. Emiel Hoogeboom, Jorn WT Peters, Rianne van den Berg, and Max Welling. Integer discrete flows and lossless compression. arXiv preprint arXiv:1905.07376, 2019. Jakub M Tomczak. General invertible transformations for flow-based generative modeling. INNF+, 2021. Michael E Tipping and Christopher M Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3):611–622, 1999. Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114, 2013. Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In International conference on machine learning, pages 1278–1286. PMLR, 2014. Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improved variational inference with inverse autoregressive flow. Advances in Neural Information Processing Systems, 29:4743–4751, 2016. Xi Chen, Diederik P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. arXiv preprint arXiv:1611.02731, 2016. Jakub Tomczak and Max Welling. VAE with a VampPrior. In International Conference on Artificial Intelligence and Statistics, pages 1214–1223. PMLR, 2018. Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien Ali Taiga, Francesco Visin, David Vazquez, and Aaron Courville. PixelVAE: A latent variable model for natural images. arXiv preprint arXiv:1611.05013, 2016. Tim R Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, and Jakub M Tomczak. Hyperspherical variational auto-encoders. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages 856–865. Association For Uncertainty in Artificial Intelligence (AUAI), 2018. Edwin T Jaynes. Probability theory: The logic of science. Cambridge university press, 2003. Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energybased learning. Predicting structured data, 1(0), 2006. David H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for Boltzmann machines. Cognitive science, 9(1):147–169, 1985. Geoffrey E Hinton, Terrence J Sejnowski, et al. Learning and relearning in Boltzmann machines. Parallel distributed processing: Explorations in the microstructure of cognition, 1(282-317):2, 1986. Geoffrey E Hinton. A practical guide to training restricted Boltzmann machines. In Neural networks: Tricks of the trade, pages 599–619. Springer, 2012. ","permalink":"https://ltecod.github.io/posts/2023/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%BA%8C/","summary":"1.1 人工智能不仅仅是决策 在思考深度生成建模之前，先看一个简单的例子：假如我们已经训练了一个对动物图像$\\boldsymbol{x}\\in\\ma","title":"【译】深度生成建模（二）"},{"content":" 虽然以生成式AI作为研究方向，但是对与各种生成式模型实在是一知半解，缺乏深入的认识。网络上的教程和解读纷繁多样，即使看过不少，不过大都囫囵吞枣，早已成过眼云烟。 😮‍💨 最近正好发现22年出版的《Deep Generative Modeling》（作者：Jakub M. Tomczak）一书，是个系统学习深度生成模型的好机会。秉着好记性不如烂笔头的精神，打算通读一遍并将其中的内容翻译记录下来，作为加深记忆理解之用。限于英语水平，且有些内容融合了个人看法，所做翻译未必与原文完全一致。 本书的序由机器学习领域大牛Max Welling而作，通读下来，感觉更像一篇随笔，其中没有对具体技术做深入阐述，只描述了对当前AI的一些看法，但其思考的问题和方式却值得学习借鉴，故将序言翻译整理如下： 在过去十年中，深度学习的崛起引领了人工智能领域的巨大进展，彻底改变了众多子领域，例如计算机视觉、语音识别和自然语言处理等。此时此刻，更多的领域正在被颠覆重塑，包括机器人学、无线通信以及各种自然科学。\n其中大部分进展都起源于监督学习。在监督学习范式下，模型的训练数据带有标注，每个样本都有对应的标签。借助于标注数据，深度神经网络在图像目标识别、翻译等任务上已取得显著成绩。但是，数据的标注过程通常十分耗时且昂贵，甚至存在道德风险或完全无法实现。因此，研究者们已意识到，无监督（或自监督）学习才是引领日后进展的关键。\n无监督学习和自监督学习与人类的学习方式类似。举例来说，在儿童的成长历程中，学习所用的信息大都无任何标记。否则的话，难道曾经时时刻刻都有人在你耳边告诉你看到了什么，听到了什么？当然不是这样，事实与之相反，我们必须在无监督的情况下学习世界的运行规律，而且是通过掌握信息（数据）中的结构或模式来学习。数据中存在大量的结构知识！假设我们通过组合像素的值获得一幅图像，其结果极有可能是毫无意义的噪声；另一方面，所有可能的像素组合（图像空间）中，绝大部分实例与我们迄今为止看到的任何图像都不一样，这意味着存在很多的数据和结构，因此对于儿童来说需要学习的东西很多。\n当然，儿童在学习的过程中不只是这个世界的旁观者，他们其实是在不断地与环境互动。在玩耍时他们会根据现实的反馈验证他们对物理、社会和心理等法则的认知。当现实与预测不同时，他们会感到惊讶，并可能更新内部的认知模型，以便下次做出更好的预测。所以，我们可以合理地假设，与环境互动的过程是达到所谓人类智能的关键。这与强化学习有着明显的相似之处，在强化学习中，智能体规划下一步的行动并根据环境的反馈更新决策或策略模型。 但是，对于机器人来说，很难通过与现实世界的互动实现假设的验证或数据的标注。因此，使用大量数据进行学习的实用方法是无监督学习。这一领域目前获得了大量的关注，且取得了惊人的进展。只需瞧瞧那些由模型轻而易举自动生成的全新人脸图像，我们就可以体验到这一领域已取得了不可思议的进步。\n无监督学习有多种形式。这本书（Deep Generative Modeling）关注其中的一种，即概率生成模型，其目标之一是估计输入数据的概率分布，可用于采样生成全新的数据实例（例如人脸图像）。另一目标是学习输入数据的抽象表示，亦称表示学习。高层次的表示会将输入数据自动解耦（disentangling）成我们所熟知的概念及其关系，例如图片中的猫和狗。虽然“解耦”有着明确直观的含义，但事实表明对他进行正确定义是相当棘手的。上世纪90年代，研究人员将大脑认知与统计层面相独立的隐变量关联起来。认为大脑的目标是将高度相关的细粒度表示（例如视觉像素）转为相对独立的隐变量表示（例如抽象概念），后者是对前者的压缩，更高效且冗余更少，从而使大脑在高效处理信息的同时耗费更少的能量。\n学习 和压缩 是两个关系紧密的概念。学习可视为对数据的有损压缩，因为学习不是简单地记住数据，而是要根据数据获得泛化能力。机器学习就是将数据集中关键的模式信息转化到模型参数中，并丢弃其他无关的信息。类似地，当我们观察一副图像时，所感兴趣的是其中的抽象概念，例如出现的物体以及联系，而不是直接的像素信息。在此基础上，我们可以对这些对象进行推理，联想出各种各样的可能性。所以，智能就是从刺激我们感官的大量低层次信息中提取出关键信息，然后进行表示以开展后续的思想活动。但我们日常生活中所熟知的事物并不是完全独立。因此，人们试图从不同的角度定义解耦，比如等变性或因果关系。\n在没有标签的情况下，训练模型最简单的方式是学习输入数据的概率生成（或密度）模型。在概率生成模型这一领域，许多方法以最大化输入的对数概率或其下界作为优化目标。除了VAE和GAN，该书还介绍了正则化流、自回归模型、能量模型以及当下最炙手可热的深度扩散模型。\n生成模型之外的很多模型也具备学习数据表示的能力，且能够有效地提升下游预测任务。针对表示学习，已出现了多种无需标注数据的训练任务，例如，针对时序数据，根据当前状态预测未来状态；针对图像，预测某一区域在另一区域的左侧还是右侧；针对视频，预测其是正向播放还是逆向播放；针对文本，根据上下文完形填空。此类无监督学习一般称为自监督学习，尽管我必须承认这个术语在不同人口中似乎有不同的用法。很多方法都可归类到上述无监督学习的范式中，包括一些生成式模型。例如，变分自编码器（VAE）将输入压缩为后验分布，然后根据压缩信息重建样本，即预测输入是什么；生成对抗网络（GAN）就是预测一个给定的样本是真实的还是虚假生成的；噪声对比估计（NCE）可看作是在隐空间预测输入片段在空间或时间上是否接近。\n很难说这个领域未来会发生什么？但显然通用人工智能（AGI）的实现将十分依赖于无监督学习。有趣的是，针对通用人工智能的实现方式，目前学界分为两大阵营：一方主张“提升规模”，认为将当前的技术应用到更大的模型上，并使用更多的数据和算力进行训练，高级智能就会自动涌现，进而实现AGI；另一方认为我们需要新的理论和想法，比如推理、因果或常识\u0026quot;。\n此外，还有一些越发重要和紧迫的问题，那就是人类应该怎样与这些模型共处：如何理解模型内部发生的事情，或者直接放弃可解释性？当模型比我们更了解我们自己时，我们的生活会发生什么改变？那些遵从算法推荐的人是否比那些抵制的人更容易成功？当模型生成的虚假数据逼真到真伪难辨，我们还能相信什么？当虚假信息泛滥之时，民主是否还能继续发挥功能？无论如何有一点非常肯定，那就是这个领域是当前最炙手可热的方向之一，而本书就是涉足这个领域的绝佳入门。但每个人也应该充分意识到，掌握这项新技术同时需要承担新的社会责任。让我们谨慎的推进这一领域的发展。\nMax Welling 2021.10.30 ","permalink":"https://ltecod.github.io/posts/2023/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%80/","summary":"虽然以生成式AI作为研究方向，但是对与各种生成式模型实在是一知半解，缺乏深入的认识。网络上的教程和解读纷繁多样，即使看过不少，不过大都囫囵吞","title":"【译】深度生成建模（一）：前言"},{"content":"","permalink":"https://ltecod.github.io/about/","summary":"","title":"About"},{"content":"","permalink":"https://ltecod.github.io/faq/","summary":"","title":"Faq"},{"content":"本站（ltecod.github.io）文章均为原创。\n本站采用 CC BY-NC-ND 4.0 协议，转载时请遵守以下条款：\n保留署名 神思豌豆 保留原文链接 不将本作品用于商业目的 如有任何内容不慎侵犯您的版权，请与我联系 jensus.yang@hotmail.com\n","permalink":"https://ltecod.github.io/copyright/","summary":"本站（ltecod.github.io）文章均为原创。 本站采用 CC BY-NC-ND 4.0 协议，转载时请遵守以下条款： 保留署名 神思豌豆 保留原文链接 不将本作品用于商","title":"版权说明"},{"content":"","permalink":"https://ltecod.github.io/tags/","summary":"","title":"标签"}]