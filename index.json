[{"content":" 虽然自己的研究方向为生成式AI的应用，但是对与各种生成式模型却是一知半解，缺乏深入的认识。网络上有各种各样的教程和解读，尽管看过不少，不过大都囫囵吞枣，早已成过眼云烟了😮‍💨。最近正好看到22年出版的《Deep Generative Modeling》（Jakub M. Tomczak）一书，感觉是个系统学习深度生成模型的好机会。秉着好记性不如烂笔头的精神，打算通读一遍并将其中的内容翻译记录下来，作为加深记忆理解之用。\n本书的序由机器学习领域大牛Max Welling而作。\n在过去的十年中，随着深度学习的发展，机器学习领域取得了巨大的进展。它已经彻底改变了人工智能所有的子领域，例如计算机视觉、语音识别和自然语言处理。此时此刻，更多领域正在被这一范式颠覆重塑，包括机器人学、无线通信和各种自然科学。\n这其中的大部分进展都来源于监督学习，其中的训练数据是带有标注的，即每个样本都有对应的标签。虽然深度神经网络在图像目标识别、语言翻译等方面变得异常出色。但是，标注数据通常非常耗时且昂贵，甚至存在道德风险或完全无法实现。因此，深度学习领域的研究者已经意识到，无监督（或自监督）方法是引领后续进展的关键。\n无监督学习和自监督学习与人类的学习方式没什么不同：在儿童的成长过程中，学习所需要的数据信息大都是无标记的。如果不是这样，难道会有人在你耳边时时刻刻告诉你看到的是什么，听到的是什么？事实是，我们必须在无监督的情况下学习世界的规律，而且是通过搜索数据中的模式或结构来做到这一点的。需要学习的结构知识有很多。为说明这一点，假设我们随机选择图像中每个像素的颜色，其结果极有可能看起来是一堆毫无意义的噪声。在所有可能的图像中，大部分都与我们睁开眼睛时看到的任何图像都不一样。这意味着存在大量的结构知识，因此儿童有很多东西需要学习。\n当然，孩子们不只是盯着这个世界看。相反，他们不断地与之互动。他们在玩耍时，会根据他们对物理法则、社会和心理的认知做出预测。当事实与预测不同时，他们会感到惊讶，并可能会更新内部模型，以便下次做出更好的预测。 我们可以合理地假设，这种互动过程是达到我们认为的人类智能的关键（具身智能）。此种类型的学习与强化学习有着明显的相似之处，在强化学习中，智能体agent规划下一步的行动（比如说下棋）并根据环境的反馈（赢还是输）更新它们的世界模型以及在所采取行动的策略。\n但很难让机器人在世界上四处移动来测试假设并主动获取自己的注释。因此，使用大量数据进行学习的更实用方法是无监督学习。这一领域获得了巨大的关注，最近取得了惊人的进展。只需看看那些我们可以毫不费力地生成且不存在的人脸图像，我们就可以体验到这一领域所取得的不可思议的进步。\n无监督学习有很多种形式。这本书（Deep Generative Modeling）专注其中的一种，我们通常称之为概率生成建模的。这一子领域的目标是估计输入数据的概率分布。一旦有了这样的模型，我们就可以从中生成新的样本（例如新人脸图像）。另一个目标是学习输入数据的抽象表示，也被称为表示学习。高级的表示会将输入数据自动解耦，形成我们所熟知的一些概念及其关系，例如图片中的猫和狗。虽然“解耦”有着明确的直观含义，但事实证明，要正确定义它是相当棘手的。在上世纪90年代，人们开始考虑在统计上相独立的隐变量。大脑的目标是将高度依赖的像素表示转换为独立隐变量的表示，后者更高效、冗余更少，从而压缩输入数据，在能量和信息上更高效。\n学习和压缩是两个关系紧密的概念。学习需要对数据进行有损压缩，因为学习是对数据的泛化，而不是存储。在数据集层面，机器学习就是将数据集中存在的一小部分关键信息转移到模型的参数中，并丢弃其他的无关的信息。\n","permalink":"http://localhost:1313/posts/2023/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%80/","summary":"虽然自己的研究方向为生成式AI的应用，但是对与各种生成式模型却是一知半解，缺乏深入的认识。网络上有各种各样的教程和解读，尽管看过不少，不过大","title":"深度生成模型（一）：前言"},{"content":"","permalink":"http://localhost:1313/about/","summary":"","title":"About"},{"content":"","permalink":"http://localhost:1313/faq/","summary":"","title":"Faq"},{"content":"","permalink":"http://localhost:1313/tags/","summary":"","title":"标签"}]